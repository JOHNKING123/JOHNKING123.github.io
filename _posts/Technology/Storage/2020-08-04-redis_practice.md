---

layout: post
title: 《Redis核心技术与实现》笔记
category: 技术
tags: Storage
keywords: Redis

---

## 前言（持续更新）

* TOC
{:toc}

文章部分内容来自对 《Redis核心技术与实现》的学习

![](/public/upload/storage/redis_overview.jpg)

## 整体架构

### 基本设计

1. 对于键值数据库而言，基本的数据模型是 key-value 模型。key 一般是 String 类型，而 value 类型则比较多样。在对键值数据库进行选型时，**一个重要的考虑因素是它支持的 value 类型**。例如，Memcached 支持的 value 类型仅为 String 类型，而 Redis 支持的 value 类型包括了 String、哈希表、列表、集合等。Redis 能够在实际业务场景中得到广泛的应用，就是得益于支持多样化类型的 value。从使用的角度来说，不同 value 类型的实现，不仅可以支撑不同业务的数据需求，而且也隐含着不同数据结构在性能、空间效率等方面的差异，从而导致不同的 value 操作之间存在着差异。
2. 对数据做什么操作？PUT/GET/DELETE/SCAN 是一个键值数据库的基本操作集合，此外还有EXISTS 等。当一个键值数据库的 value 类型多样化时，也需要包含相应的操作接口。例如，Redis 的 value 有列表类型，因此它的接口就要包括对列表 的操作。
3. 键值对保存在内存还是外存？
4. 采用什么访问模式？通过函数库调用的方式供外部应用使用，比如RocksDB；通过网络框架以 Socket 通信的形式对外提供键值对操作，通过网络框架提供键值存储服务，一方面扩大了键值数据库的受用面，但另一方面，也给键值数据库的性能、运行模型提供了不同的设计选择，带来了一些潜在的问题。
5. 如何定位键值对的位置？这依赖于键值数据库的索引模块。索引的作用是让键值数据库根据 key 找到相应 value 的存储位置，进而执行操作。一般而言，内存键值数据库（例如 Redis）采用哈希表作为索引，而 RocksDB 则采用跳表作为内存中 key-value 的索引（估计是减少索引占用的磁盘空间，减少索引带来的磁盘io）。
6. 内存分配，键值对的增删改往往伴随着内存的分配和回收，Redis 的内存分配器提供了多种选择，分配效率也不一样
7. 持久化

### 键和值用什么结构组织？

哈希表。因为这个哈希表保存了所有的键值对，所以，我也把它称为**全局哈希表**。

![](/public/upload/storage/redis_kv.png)

查找过程主要依赖于哈希计算（O(1) 复杂度），和数据量的多少并没有直接关系。但是，当你往 Redis 中写入大量数据后，还是会发现操作有时候会突然变慢了，因为哈希表的冲突问题和 rehash 可能带来的操作阻塞。为了使 rehash 操作更高效，Redis 默认使用了两个全局哈希表：哈希表 1 和哈希表 2。一开始，当你刚插入数据时，默认使用哈希表 1，此时的哈希表 2 并没有被分配空间。随着数据逐步增多，Redis 开始执行 rehash，这个过程分为三步：
1. 给哈希表 2 分配更大的空间，例如是当前哈希表 1 大小的两倍；
2. 把哈希表 1 中的数据重新映射并拷贝到哈希表 2 中； 为了避免copy 过程阻塞用户请求，Redis 采用了渐进式 rehash，每处理一个请求时，从哈希表 1 中的第一个索引位置开始，**顺带着**将这个索引位置上的所有 entries 拷贝到哈希表 2 中。PS：跟redis 通过用户请求顺带清理 过期数据是一样的。
3. 释放哈希表 1 的空间。

因为 Redis 的数据类型有很多，而且，不同数据类型都有些相同的元数据要记录（比如最后一次访问的时间、被引用的次数等），所以，Redis 会用一个 RedisObject 结构体来统一记录这些元数据，同时指向实际数据。一个 RedisObject 包含了 8 字节的元数据和一个 8 字节指针，这个指针再进一步指向具体数据类型的实际数据所在，当然也有例外，为了节省内存空间，Redis 还对 Long 类型整数和 SDS 的内存布局做了专门的设计。
1. 当保存的是 Long 类型整数时，RedisObject 中的指针就直接赋值为整数数据了，这样就不用额外的指针再指向整数了，节省了指针的空间开销。
2. 当保存的是字符串数据，并且字符串小于等于 44 字节时，RedisObject 中的元数据、指针和 SDS 是一块连续的内存区域，这样就可以避免内存碎片。

```c++
#define REDIS_LRU_BITS 24
typedef struct redisObject {
    unsigned type:4;        // 类型
    unsigned encoding:4;    // 编码
    unsigned lru:REDIS_LRU_BITS; // 对象最后一次被访问的时间
    int refcount;   // 引用计数
    void *ptr;  // 指向实际值的指针，可以指向不同的数据类型

} robj;
```

### 底层数据结构

Redis 为什么性能突出呢？一方面因为它是内存数据库，另一方面要归功于它的数据结构。这是因为，键值对是按一定的数据结构来组织的，操作键值对最终就是对数据结构进行增删改查操作，所以高效的数据结构是 Redis 快速处理数据的基础。String/List/Hash/Set/SortedSet 是Redis 中value的数据类型，这里说的数据结构 是底层实现，底层数据结构一共有 6 种。可以看到，String 类型的底层实现只有一种数据结构，也就是简单动态字符串。而 List、Hash、Set 和 Sorted Set 这四种数据类型，都有两种底层实现结构。

![](/public/upload/storage/redis_data_structure.jpg)


## 持久化/单机高可用

1. AOF：记录操作，对命令执行影响小， 但恢复时间较长。
2. RDB：记录的是某一时刻的数据，

可以与 mysql 的redo/undo log 对比找找感觉。

### AOF

Redis 的持久化主要有两大机制，即 AOF 日志和 RDB 快照

AOF： 我们比较熟悉的是数据库的写前日志（Write Ahead Log, WAL），也就是说，在实际写数据前，先把修改的数据记到日志文件中，以便故障时进行恢复。不过，AOF 日志正好相反，它是写后日志，“写后”的意思是 Redis 是先执行命令，把数据写入内存，然后才记录日志。

1. AOF 里记录的是 Redis 收到的每一条命令，这些命令是以文本形式保存的。Redis 在向 AOF 里面记录日志的时候，并不会先去对这些命令进行语法检查。所以，如果先记日志再执行命令的话，日志中就有可能记录了错误的命令。而写后日志这种方式，就是先让系统执行命令，只有命令能执行成功，才会被记录到日志中，否则，系统就会直接向客户端报错。
2. 在命令执行后才记录日志，所以不会阻塞当前的写操作。

AOF 也有两个潜在的风险，都是和 AOF 写回磁盘的时机相关
1. 如果刚执行完一个命令，还没有来得及记日志就宕机了，那么这个命令和相应的数据就有丢失的风险。
2. AOF 虽然避免了对当前命令的阻塞，但可能会给下一个操作带来阻塞风险。因为AOF 日志也是在主线程中执行的，如果在把日志文件写入磁盘时，磁盘写压力大，就会导致写盘很慢，进而导致后续的操作也无法执行了。

对于这个问题，AOF 机制给我们提供了三个选择控制写入磁盘的时机，对应appendfsync配置 （mysql redolog/binlog都有类似的配置）

1. Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；
2. Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；
3. No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。

AOF日志文件太大了怎么办？AOF 重写机制就登场了。
1. AOF 重写机制就是在重写时，Redis 根据数据库的现状创建一个新的 AOF 文件。也就是说，读取数据库中的所有键值对，然后对每一个键值对用一条命令记录它的写入。PS：存在一个键值对被多条写命令反复修改的情况，这样一来，一个键值对在重写日志中只用一条命令就行了
2. 每次执行重写时，主线程 fork 出后台的 bgrewriteaof 子进程。此时，fork 会把主线程的内存拷贝一份给 bgrewriteaof 子进程，这里面就包含了数据库的最新数据。然后，bgrewriteaof 子进程就可以在不影响主线程的情况下，逐一把拷贝的数据写成操作，记入重写日志。
3. 主线程未阻塞，仍然可以处理新来的操作。如果有写操作，除了正在写的AOF 日志，还会再写一份AOF 重写日志。等到bgrewriteaof 拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件，此时，就可以用新的 AOF 文件替代旧文件了。

![](/public/upload/storage/aof_rewrite.jpg)

### RDB（Redis DataBase）

把某一时刻的状态以文件的形式写到磁盘上，也就是快照。在做数据恢复时，可以直接把 RDB 文件读入内存，很快地完成恢复。Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave。

1. save：在主线程中执行，会导致阻塞；
2. bgsave：创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是 Redis RDB 文件生成的默认配置。
    1. 此时，主线程的确没有阻塞，可以正常接收请求，但是，为了保证快照完整性，它只能处理读操作，不能修改正在执行快照的数据。
    2. Copy-On-Write, COW：为了快照而暂停写操作，肯定是不能接受的。bgsave 子进程是由主线程 fork 生成的，可以共享主线程的所有内存数据。bgsave 子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB 文件。如果主线程要修改一块数据，这块数据就会被复制一份，生成该数据的副本。然后，bgsave 子进程会把这个副本数据写入 RDB 文件。PS：有点 主线程既写AOF 又写AOF 重写日志的感觉。

![](/public/upload/storage/rdb_cow.jpg)

快照的频率不好把握，如果频率太低，两次快照间一旦宕机，就可能有比较多的数据丢失。如果频繁地执行全量快照，也会带来两方面的开销。一方面，频繁将全量数据写入磁盘，会给磁盘带来很大压力，多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。bgsave 子进程需要通过 fork 操作从主线程创建出来。虽然，子进程在创建后不会再阻塞主线程，**但是fork 这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长**（所以使用RDB时，单个实例的redis 内存不宜过大）。有什么两全其美的招么？Redis 4.0 中提出了一个混合使用 AOF 日志和内存快照的方法。简单来说，内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。

## 主从同步/多机高可用

Redis 提供了主从库模式（副本一致采用强leader模型），主从库同步是如何完成的呢？主库数据是一次性传给从库，还是分批同步？主从间网络中断怎么办？

1. 主从库间如何进行第一次同步？当我们启动多个 Redis 实例的时候，它们相互之间就可以通过 replicaof（Redis 5.0 之前使用 slaveof）命令形成主库和从库的关系

    ![](/public/upload/storage/master_slave_first_sync.jpg)
2. 主从级联模式分担全量复制时的主库压力。一次全量复制中，对于主库来说，需要完成两个耗时的操作：生成 RDB 文件和传输 RDB 文件。如果从库数量很多，而且都要和主库进行全量复制的话，就会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量同步。fork 这个操作会阻塞主线程处理正常请求，从而导致主库响应应用程序的请求速度变慢。此外，传输 RDB 文件也会占用主库的网络带宽，同样会给主库的资源使用带来压力。那么，有没有好的解决方法可以分担主库压力呢？其实是有的，这就是“主 - 从 - 从”模式。
2. 主从库断连怎么办？ replication buffer 和 repl_backlog_buffer。repl_backlog_buffer 是一个环形缓冲区，主库会记录自己写到的位置master_repl_offset，从库则会记录自己已经读到的位置slave_repl_offset。主从库的连接恢复之后，从库首先会给主库发送 psync 命令，并把自己当前的 slave_repl_offset 发给主库，主库会判断自己的 master_repl_offset 和 slave_repl_offset 之间的差距。增量复制

主库挂了怎么办？ 哨兵其实就是一个运行在特殊模式下的 Redis 进程，三个任务：监控、选主（选择主库）和通知。
1. 监控。周期性地给所有的主从库发送 PING 命令，检测它们是否仍然在线运行。如果从库没有在规定时间内响应哨兵的 PING 命令，哨兵就会把它标记为“下线状态”；同样，如果主库也没有在规定时间内响应哨兵的 PING 命令，哨兵就会判定主库下线，然后开始自动切换主库的流程。
2. 选主。筛选+打分，在多个从库中，先按照一定的筛选条件，把不符合条件的从库去掉（在线状态、断连次数）。然后，我们再按照一定的规则，给剩下的从库逐个打分（从库优先级、从库复制进度= master_repl_offset-slave_repl_offset 以及从库 ID 号），将得分最高的从库选为新主库。PS：有点k8s 调度的感觉
3. 通知。哨兵会把新主库的连接信息发给其他从库，让它们执行 replicaof 命令，和新主库建立连接，并进行数据复制。同时，哨兵会把新主库的连接信息通知给客户端，让它们把请求操作发到新主库上。

## 切片集群

Redis Cluster 方案采用哈希槽（Hash Slot，接下来我会直接称之为 Slot），来处理数据和实例之间的映射关系。一个切片集群共有 16384 个哈希槽，键值对的 key，按照CRC16 算法计算一个 16 bit 的值；然后，再用这个 16bit 值对 16384 取模。在部署 Redis Cluster 方案时，可以使用 cluster create 命令创建集群，此时，Redis 会自动把这些槽平均分布在集群实例上（当然也可以手动配置）。通过哈希槽，切片集群就实现了数据到哈希槽、哈希槽再到实例的分配。

如何知道哈希槽分布在哪个实例上？Redis 实例会把自己的哈希槽信息发给和它相连接的其它实例，来完成哈希槽分配信息的扩散。当实例之间相互连接后，每个实例就有所有哈希槽的映射关系了。客户端收到哈希槽信息后，会把哈希槽信息缓存在本地。当客户端请求键值对时，会先计算键所对应的哈希槽，然后就可以给相应的实例发送请求了。

在集群中，实例和哈希槽的对应关系并不是一成不变的，会有增删节点、负载均衡等情况， 此时，实例之间还可以通过相互传递消息，获得最新的哈希槽分配信息，但是，客户端是无法主动感知这些变化的。Redis Cluster 方案提供了一种重定向机制，当客户端把一个键值对的操作请求发给一个实例时，如果这个实例上并没有这个键值对映射的哈希槽，那么，这个实例就会给客户端返回下面的 MOVED 命令响应结果，这个结果中就包含了新实例的访问地址。客户端更新本地缓存的哈希槽信息，并向新实例发送操作请求。如果哈希槽对应的数据正在迁移，客户端就会收到一条 ASK 报错信息，于是客户端向新实例发送操作请求，但不会更新本地缓存。
```
GET hello:key
(error) MOVED 13320 172.16.19.5:6379
GET hello:key
(error) ASK 13320 172.16.19.5:6379
```

## 其它

1. 全量复制虽然耗时，但是对于从库来说，如果是第一次同步，全量复制是无法避免的，所以一个小建议：一个 Redis 实例的数据库不要太大，一个实例大小在几 GB 级别比较合适，这样可以减少 RDB 文件生成、传输和重新加载的开销。

![](/public/upload/storage/redis_practice_class.jpg)