---

layout: post
title: k8s的2017
category: 技术
tags: Kubernetes
keywords: kubernetes 2017

---

## 简介


[2018：Kubernetes迎来成长之痛](https://zhuanlan.zhihu.com/p/32874937)2017年，Kubernetes已经有效地赢得了容器编排的战争，Docker Swarm、Mesos和Pivotal这样的竞争对手都宣布将在自己的平台里增加对Kubernetes的支持

在16年底17年初，笔者进行测试环境容器化的时候，swarm已处于劣势，k8s和mesos难分伯仲，考虑到

1. mesos有现成的方案与实践，笔者身边的一些公司如B站、沪江也在使用
2. k8s的三大基本概念pod、service、replication controller。

	* pod概念用不上，就是一个web服务运行在tomcat中，编排工具负责部署就可以了；[解读2017之容器篇：后Kubernetes时代](http://www.infoq.com/cn/articles/2017-container-Kubernetes)提到：甚至在2017年初，Kubernetes的Pod以及Pod所体现出来的“解耦容器关系”的设计模式，依然时常被质疑为“用处不大”或者“过度设计”。
	* service 略复杂，尤其当macvlan方案实现容器ip与物理机任意互访之后，sevice便显得有些多余。
	* replication controller 比较有用，但mesos/marathon的health check 基本也可以实现这个需求。

因此，当时选择了mesos，恩，一个现在看略尴尬，但也没啥问题的选择。尴尬在于，我们选错了。没啥问题在于，以当时的情况，确实对很多问题缺乏认识。

本文主要内容：

1. 重新认识k8s的一些理念
2. 因为笔者的k8s实践截止到了16年底，本文汇总下k8s在2017年的变化

	* api对象的扩充
	* 开放接口
## 重新认识k8s的一些理念

Kubernetes项目从开始设计之初就高度重视的一项关键诉求：

1. 从上层API到底层容器运行时，Kubernetes工作流中的每个环节，都希望具备完善的可扩展性。

	* CNI、CRI等一系列良好设计的通用接口来实现不同类型、不同功能的网络和容器运行时
	* API Aggregation扩展Kubernetes API Server从而支持自定义资源监控格式并以此来做Auto-Scaling
2. Kubernetes任何功能特性的设计和实现，都尽可能针对更通用的用户场景而非特定需求。


[解读2017之容器篇：后Kubernetes时代](http://www.infoq.com/cn/articles/2017-container-Kubernetes)提到：Kubernetes刚发起的时候，其核心的理念来自几位“Elder（元老）”的构想，他们大多是Borg和Omega项目的开发者或者架构师，一直专注于如何在没有cloud的场景下构建足够规模的通用Infrastructure Layer的实践。**Infrastructure Layer 或许才是k8s更本质的东西，作为一个layer，辅助以社区的力量，可编程，可扩展。**而mesos/marathon 更多像一个顶层工具，需要一个功能时，除非它提供这个功能，否则束手无策。

[kubernetes-handbook](https://jimmysong.io/kubernetes-handbook)kubernetes的目标不仅仅是一个编排系统，而是提供一个规范，可以让你来描述集群的架构，定义服务的最终状态，kubernetes可以帮你将系统自动得达到和维持在这个状态。

更直白的说，Kubernetes用户可以通过编写一个yaml或者json格式的配置文件，也可以通过工具/代码生成或直接请求kubernetes API创建应用，该配置文件中包含了用户想要应用程序保持的状态，不论整个kubernetes集群中的个别主机发生什么问题，都不会影响应用程序的状态，你还可以通过改变该配置文件或请求kubernetes API来改变应用程序的状态。

## api 对象的扩充

API对象是Kubernetes集群中的管理操作单元。Kubernetes集群系统每支持一项新功能，引入一项新技术，一定会新引入对应的API对象，支持对该功能的管理操作。例如副本集Replica Set对应的API对象是RS。

每个API对象都有3大类属性：元数据metadata、规范spec和状态status。

pod、service、rc之外的新api对象

1. 部署增强。副本集（Replica Set，RS），新一代rc；Deployment
2. 业务类型增强。任务（Job）和后台支撑服务集（DaemonSet） 
3. 有状态服务集（PetSet）
4. 集群联邦（Federation）
5. 存储卷（Volume）、持久存储卷（Persistent Volume，PV）

概括下来

1. 细化支持不同类型的服务
	1. 针对不同的服务类型，提供的不同的管理能力。比如除web服务外，有状态服务、日志服务（需要每个主机上跑一个）等
2. 将更多的资源纳入到调度或管理中
	2. 扩大了集群范围，跨机房、跨服务商等
	3. 存储卷、Node
3. 提高安全性

## 开放接口

1. cri。不准确的说，mesos调度容器，应该是mesos-master 向mesos-slave 发送命令，mesos-slave 执行`docker run xxx` 来运行容器。k8s 则直接促使其它厂商支持其定义的cri 接口，从` rpc RunPodSandbox(RunPodSandboxRequest) returns (RunPodSandboxResponse) {}`之类的接口可以看到，要求支持cri的厂商支持自家的pod概念

	![](/public/upload/kubernetes/cri.png)
	
2. cni。这里主要说下cni插件和ipam 插件的关系。cni插件所做的事情，简单说就是：为容器添加network namespace，并配置其可用的过程。从cni插件中又独立出来ipam，负责ip的管理与分配
3. csi。笔者理解较浅显，但看到了两种可能性：一，不同的服务可以挂载不同的volume，由配置指定；二，一个服务重启时，虽然运行主机变了，但仍可以挂载原先的volume，这对部署有状态服务意义重大。而docker 只能使用本地volume，本地volume 挂载全局分布式文件系统来实现类似的效果。估计这也是，csi 提高到编排层面的好处所在。


学习csi 的文章 [Container Storage Architectures: How Does Kubernetes, Docker, and Mesos Compare?](https://blog.thecodeteam.com/2017/06/27/container-storage-architectures-kubernetes-docker-mesos-compare/)几个要点

1. Containers promise application portability far beyond what virtualization can achieve because the hypervisor has requirements for hardware emulation（相比hypervisor，Containers极大的提高了application的可移植性）. The ability to achieve application portability is going to rely on interoperability amongst container orchestrators. Even with modern cloud-native applications, storage is a critical component because applications can take advantage of persistent storage platforms and develop around some of its features. See Clint Kitson’s blog [Understanding Storage in a Cloud Native Context for more information](https://blog.thecodeteam.com/2017/05/16/understanding-storage-cloud-native-context/).

2. 未完成

有这个三个开放接口，笔者有一个感觉（还有待考证）

1. 一开始docker 掌控一切，docker掌控容器的网络（veth挂载网桥上）、持久存储（本地磁盘）。此时，容器的能力也有限。
2. docker 将一些能力放开，提出了plugin的概念，docker与插件之间通过http 交互。docker创建容器，需要ip时与ipam交互，需要存储时，与volume plugin交互。
3. 此时，docker仍然掌控着全局，虽说plugin 的部署在docker 之外。但如果docker运维和使用是两批人的话，使用者还无法决定创建的容器使用哪个volume plugin
4. k8s 通过cri、cni、csi三大接口，docker 退化成了一个cri实现（也就是cpu与内存资源的封装）。

## 从k8s上学到的

### api 设计原则

**高层API以操作意图为基础设计**。如何能够设计好API，跟如何能用面向对象的方法设计好应用系统有相通的地方，**高层设计一定是从业务出发，而不是过早的从技术实现出发。**低层API根据高层API的控制需要设计。设计实现低层API的目的，是为了被高层API使用，考虑减少冗余、提高重用性的目的，低层API的设计也要以需求为基础，要尽量抵抗受技术实现影响的诱惑。

1. 声明式api，设置pod replicas = 3，可以多次执行、重试
2. 命令式api，设置pod replicas + 1，不可以多次执行、重试

## 小结

笔者之前采用的测试环境docker化方案是mesos + marathon，如果只是将一个java web服务部署到docker上，那么mesos仍然是够用的。但其抽象还是太简单了：类似于hadoop的思路，一面采集汇总slave资源，一面将docker作为载体调度任务运行。但是

1. 接口封闭，无法随意扩展。只能依赖mesos 官方支持
2. 并没有完全解决微服务部署的各方面问题，比如：使用mesos部署java web服务后，日志采集仍然部署在物理机上；有状态服务部署在docker上仍然缺乏支持等。

归根到底，mesos还只是docker的使用者，也必然是docker特性的迁就者。而k8s则试图将一切掌握在自己手中，只给docker留一个cri的位置。比如，正式csi的提出，k8s才具备条件管理有状态服务（**k8s的大部分特性，不是说原来的docker或者后来的mesos做不到，而是k8s将这一切规范了、可配置、可管理了**）。

docker之于mesos，像西欧的国王与领主；docker之于k8s，像是皇帝与巡抚。都是从上到下管理民众，但皇帝却可以在巡抚之外，搞出总督、河道总督、御史之类的东东，以灵活的应对各种问题。因为本质上资源在皇帝，而不是巡抚手中。