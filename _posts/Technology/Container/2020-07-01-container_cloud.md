---

layout: post
title: 对容器云平台的理解
category: 技术
tags: Container
keywords: docker

---

## 简介

* TOC
{:toc}

## 组成内容

一开始只是基于k8s api 做了个发布系统，在容器化落地过程中，单单一个发布系统是远远不够的，对要做的事情做了一个梳理。

0. 基础组件改造/增强
    1. lxcfs 让容器内进程 感受到真实配给给容器的资源
    2. 镜像分发加速
1. 发布系统
	1. 基于代码制作镜像
	2. 项目发布 四元组
	3. 无损发布 健康检查 与网关、mainstay 的对接==> 掌握的项目数据必须是准确的
	4. 发布历史、回滚、扩缩容、服务画像（优先级、基于标签的调度）
2. 研发支持：日志采集、web shell、相关信息写入环境变量、隔离组、故障探测工具
3. 资源管理中心：mysql、pika、redis、mq、kafka 等容器化
4. 监控系统 态势感知，可观测性。
	1. 项目维度 cpu、内存使用情况、java 特殊性（jvm 感知cpu、内存大小、堆外内存限制）、事件流
	2. 集群维度 cpu 内存使用，事件中心，核心组件在线（k8s 几大组件、kubelet、docker、calico）
	3. 存储组件 mysql、redis、pika、mq 等
	4. 承载组件：prometheus 
	==> 出了事儿有必要的数据 辅助排查问题
5. 报警   
	1. 项目 健康检查异常、cpu、内存紧张异常、mainstay 是否在线、必须存在stable 隔离组实例
	2. 集群 资源异常、磁盘损坏异常、有多少反亲和的服务运行在同一个机器上
	3. 报警策略  报给谁、频度怎么样、对方不处理怎么办
	4. 承载组件：一个 Doraemon + 基于模板的报警系统 能不能承载下来？

## 几个囧事

1. 业务方反馈，容器时不时就没了，当时无从排查，搞不清楚是主动调度没的（只是新的实例没启动成功） 还是占用内存过大oom 没的。
2. 测试同学抱怨测试环境不稳定，难以量化和评估。很多开发项目出问题后就是简单的重启，没有反馈到容器开发这边，导致容器开发对实际问题感知不足。
