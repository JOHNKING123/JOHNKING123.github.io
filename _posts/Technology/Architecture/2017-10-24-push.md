---

layout: post
title: 推送系统的几个基本问题
category: 技术
tags: Architecture
keywords: push

---

## 简介（未完成）

## 功能问题


1. 推送系统和推送服务商关系
	
	推送服务商只是实现了到设备的可达性，什么时候和发什么，仍有推送系统决定

2. 推送系统日志采集与问题排查
	* 唯一id关联推送的各个阶段
	* 排查需求：某人为什么没收到消息

	所以日志中应该包括：时间，用户，消息三个基本信息
	
	* 统计需求：每天的发送、接收和点击；一个全局推、推广推送的发送、接收和点击

3. 通道选择
	
	* 客户端的轮询是否也可以作为一个通道（跟现有的消息中心类似）
	* 长连接通道（针对即时性要求较高的业务）
	* 推送服务商通道

4. 推送过滤

	* 根据用户设置、频控、用户打开时间
	* 计算用户对推送内容的兴趣程度决定是否推送
	* 两个互斥的业务

	第一个是变化不大的，后两个则每天都会变化，如何动态插拔过滤规则
	
5. 送达数和点击数的利用

	* 分析用户兴趣
	* 评估推送效果
6. 面向使用者接口

	* 关键就是消息model的定义。消息id，基本内容，客户端行为

7. 客户端的准备

	* 各个通道，统一消息model的处理

8. 推送对其它系统的作用

	* 提高用户对业务的粘性

9. 各个系统之间的数据格式
10. 优化设计

	* 消息调度
	* 负载隔离，比如直播服务及时性要求较高，全局推及时性要去低，两者不应共用同一个服务器

11. 推送需求

	* 一般业务通知，与用户相关。比如“比如您订阅的xx更新了”
	* 平台推广/用户唤醒，一个用户一天至少收到一次。全局推送 + 个性化推送
	* 部分用户群体，特定信息通知。

	
## 整体设计

几个名词：

1. uid/device id，公司内部对用户/设备的标记
2. token，推送服务商（小米、个推）对设备的标记

推送的基本流程

1. 公司内需求方 发送 `<uid,msg>` 要求向特定用户推送
2. 根据 uid 查询 用户设置、频控、亲密度 等服务，判定是否向用户发送推送
3. 根据uid 查询对应的token ，调用推送服务商接口 发送`<token,msg>` 

因此，提炼出以下基本模块

1. 推送调用方
2. 过滤服务
3. 推送服务

简单方案：模块之间采用消息队列连接

问题：出现大v的相关事件推送时，会堵。在该方案下，任何优化（包括批量、动态调度）都只是小有提高，无法从根本上解决问题。

## 推送中的代码设计问题

data processing system 和 普通的后端业务开发。 

我们知道，一开始开发只有业务开发。后来因为大数据的火爆，产生了数据开发。两者有何差异呢？

1. 一个显式的区别是，业务开发使用springmvc、dubbo 等构建业务逻辑。数据开发使用hadoop、spark 等处理业务。数据开发 后来分化为 批量处理和实时处理
2. 后端请求处理多为集中式的，一个http 请求落在哪个服务器上，该服务器调用rpc/jdbc/redis 等从各个服务器抓取数据过来，根据业务要求 得到返回结果。计算是集中的，数据是分布的。
3. 数据处理 多为分布式的，对于批量处理，因为数据量大，所以将数据分拆，计算跟着数据走。对于storm 等，则将计算分散在多个主机上，扩大数据的处理能力。不算数据是否集中，计算都是分散的
4. 什么是数据处理，我们看spark 等提供的接口：过滤、转换、组合等。而业务处理通常类似于根据uid查询用户信息，用户发个评论数据库新增一条记录。

由此，我们可以看到，**推送系统属于一个 data processing system** ，拿普通的spring、springmvc、rpc调用那一套来实现 数据处理逻辑就会很难受。

因此，理想情况下，应使用storm来替换 模块+消息队列的 处理方案。而对于过滤模块内，则可以使用 apache commons-pipeline来实现 单机storm 的效果（两者的抽象非常相似）。



## 性能问题

1. 全局推和个性化推送的冲突问题

	* 全局推顺序查询数据库，个性化推送随机查询数据库
	* 全局推和个性化推送量都比较大，同时进行时，系统不堪重负

2.  对于一个http 请求， 10ms 和 20ms 差距不大，因为用户感知不到。但是对于推送系统，请求却是累积的。比如我现在要给几百万用户发个推送，并且因为业务的原因（比如直播）要求几分钟内推完。从完成任务总量的时间来说，单个请求10ms和20ms 就是翻倍的性能差距